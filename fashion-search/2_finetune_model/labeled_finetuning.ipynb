{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "12d4ff3b-022c-492a-a0d5-65f11d05dcb4",
      "metadata": {
        "id": "12d4ff3b-022c-492a-a0d5-65f11d05dcb4"
      },
      "source": [
        "# üìâ Finetuning Our Model for Better Results\n",
        "\n",
        "In our previous notebook we [built a simple fashion search engine using Docarray](https://colab.research.google.com/github/alexcg1/neural-search-notebooks/blob/main/fashion-search/1_build_basic_search/basic_search.ipynb).\n",
        "\n",
        "Now we'll finetune our model using [Jina Finetuner](https://finetuner.jina.ai) to deliver better results!\n",
        "\n",
        "### The skinny on Jina Finetuner\n",
        "\n",
        "Finetuner lets you tune the weights of any deep neural network for better embeddings on search tasks. It accompanies [Jina](https://github.com/jina-ai/jina) to deliver the last mile of performance for domain-specific neural search applications.\n",
        "\n",
        "üéõ **Designed for finetuning**: a human-in-the-loop deep learning tool for leveling up your pretrained models in domain-specific neural search applications.\n",
        "\n",
        "üî± **Powerful yet intuitive**: all you need is finetuner.fit() - a one-liner that unlocks rich features such as siamese/triplet network, metric learning, self-supervised pretraining, layer pruning, weights freezing, dimensionality reduction.\n",
        "\n",
        "‚öõÔ∏è **Framework-agnostic**: promise an identical API & user experience on PyTorch, Tensorflow/Keras and PaddlePaddle deep learning backends.\n",
        "\n",
        "üßà **[DocArray](https://docarray.jina.ai) integration**: buttery smooth integration with DocArray, reducing the cost of context-switch between experiment and production."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bdaade9-7845-47b9-8c3d-34ecbdc78467",
      "metadata": {
        "id": "6bdaade9-7845-47b9-8c3d-34ecbdc78467"
      },
      "source": [
        "##  1Ô∏è‚É£ Before you start\n",
        "\n",
        "If you're in Colab, ensure you have GPU selected as runtime. This will speed up processing. You can find it in *Runtime* ‚ñ∂Ô∏è *Change runtime type*\n",
        "\n",
        "![](https://github.com/alexcg1/neural-search-notebooks/raw/main/fashion-search/2_finetune_model/images/runtime.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9505310b-afca-42fd-98ae-a6298d915498",
      "metadata": {
        "id": "9505310b-afca-42fd-98ae-a6298d915498"
      },
      "source": [
        "## ‚öôÔ∏è Setup"
      ]
    },
    {
      "cell_type": "code",
      "id": "019105bc-6f69-47f4-a18c-43d0f33226de",
      "metadata": {
        "id": "019105bc-6f69-47f4-a18c-43d0f33226de"
      },
      "outputs": [],
      "source": [
        "LABEL = \"gender\" # Tag in doc.tags that will be used as finetuner labeler"
      ]
    },
    {
      "cell_type": "code",
      "id": "581660fa-3372-4b59-802a-80cb906285b1",
      "metadata": {
        "id": "581660fa-3372-4b59-802a-80cb906285b1"
      },
      "outputs": [],
      "source": [
        "# Check if we're running in Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    in_colab = True\n",
        "except:\n",
        "    in_colab = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2ca05e5-9609-4c15-89bc-ef3616380a14",
      "metadata": {
        "id": "b2ca05e5-9609-4c15-89bc-ef3616380a14"
      },
      "outputs": [],
      "source": [
        "!pip install torchvision~=0.11\n",
        "!pip install finetuner==0.4\n",
        "!pip install \"docarray[full]==0.4.4\""
      ]
    },
    {
      "cell_type": "code",
      "id": "61a76be3-4607-4a2b-815b-75b2749e6384",
      "metadata": {
        "id": "61a76be3-4607-4a2b-815b-75b2749e6384"
      },
      "outputs": [],
      "source": [
        "from docarray import Document, DocumentArray\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from finetuner.tuner.pytorch.losses import TripletLoss\n",
        "from finetuner.tuner.pytorch.miner import TripletEasyHardMiner"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c58e62d3-7001-493b-a718-bd3de8a9ea13",
      "metadata": {
        "id": "c58e62d3-7001-493b-a718-bd3de8a9ea13"
      },
      "source": [
        "## üñºÔ∏è Load images\n",
        "\n",
        "This is just the same process we followed in the last notebook"
      ]
    },
    {
      "cell_type": "code",
      "id": "3c7c4c90-3fd6-406b-a0d5-fce2b09b720f",
      "metadata": {
        "id": "3c7c4c90-3fd6-406b-a0d5-fce2b09b720f"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"./data\"\n",
        "DATA_PATH = f\"{DATA_DIR}/*.jpg\"\n",
        "MAX_DOCS = 1000\n",
        "\n",
        "# Toy data - If data dir doesn't exist, we'll get data of ~800 fashion images from here\n",
        "TOY_DATA_URL = \"https://github.com/alexcg1/neural-search-notebooks/blob/main/fashion-search/data.zip?raw=true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "486c94fc-9af1-40b2-be7a-17091c3077c0",
      "metadata": {
        "id": "486c94fc-9af1-40b2-be7a-17091c3077c0"
      },
      "outputs": [],
      "source": [
        "# Download images if they don't exist\n",
        "import os\n",
        "\n",
        "if not os.path.isdir(DATA_DIR) and not os.path.islink(DATA_DIR):\n",
        "    print(f\"Can't find {DATA_DIR}. Downloading toy dataset\")\n",
        "    !wget \"$TOY_DATA_URL\" -O data.zip\n",
        "    !unzip -q data.zip # Don't print out every darn filename\n",
        "    !rm -f data.zip\n",
        "else:\n",
        "    print(f\"Nothing to download. Using {DATA_DIR} for data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "071c0b91-ac0a-4d62-a5e7-509a4bd051e6",
      "metadata": {
        "id": "071c0b91-ac0a-4d62-a5e7-509a4bd051e6"
      },
      "source": [
        "## We need labels for our Documents to aid in finetuning"
      ]
    },
    {
      "cell_type": "code",
      "id": "fef8769c-69b6-44fa-904f-f076cbecdca0",
      "metadata": {
        "id": "fef8769c-69b6-44fa-904f-f076cbecdca0"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "docs = DocumentArray()\n",
        "\n",
        "DATA_FILE = f\"{DATA_DIR}/styles.csv\"\n",
        "\n",
        "with open(DATA_FILE, \"r\") as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        if row[\"id\"].startswith(\"20\"): # All filenames in ./data begin with \"20\"\n",
        "            doc = Document(uri=f\"{DATA_DIR}/{row['id']}.jpg\")\n",
        "            doc.tags = dict(row)\n",
        "            doc.tags[\"finetuner_label\"] = row[LABEL]\n",
        "            docs.append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aa2b05c-9173-4326-8bc8-306363223053",
      "metadata": {
        "id": "4aa2b05c-9173-4326-8bc8-306363223053"
      },
      "outputs": [],
      "source": [
        "def preproc(doc):\n",
        "    return (\n",
        "        doc.load_uri_to_image_tensor(80, 60) # input images are 60x80 px\n",
        "        .set_image_tensor_normalization()\n",
        "        .set_image_tensor_channel_axis(-1, 0)\n",
        "    )\n",
        "\n",
        "\n",
        "docs.apply(preproc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ca2c73f-850a-4a27-b1c5-dae65a5e14fe",
      "metadata": {
        "id": "7ca2c73f-850a-4a27-b1c5-dae65a5e14fe"
      },
      "source": [
        "## üß† Load model\n",
        "\n",
        "Again, we're playing the same old song, loading a model just like we did last time. Once again we're using trusty old `resnet50`."
      ]
    },
    {
      "cell_type": "code",
      "id": "4bc4d290-12ce-4c49-80c1-d11f3fbb305a",
      "metadata": {
        "id": "4bc4d290-12ce-4c49-80c1-d11f3fbb305a"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "\n",
        "model = torchvision.models.resnet50(pretrained=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6f522e8-c0cf-4e5c-9102-7d687052b1d0",
      "metadata": {
        "id": "b6f522e8-c0cf-4e5c-9102-7d687052b1d0"
      },
      "source": [
        "### See embeddings\n",
        "\n",
        "Let's take a look at our embeddings to see how good the current (un-finetuned) model is. In Google Colab we need to install some extra libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e16ec1fe-77a0-4550-8a1d-a8dba13b5f42",
      "metadata": {
        "tags": [],
        "id": "e16ec1fe-77a0-4550-8a1d-a8dba13b5f42"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = \"cuda\"\n",
        "else:\n",
        "    DEVICE = \"cpu\"\n",
        "\n",
        "docs.embed(model, device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b927a7ab-fbdc-4dab-b5bb-ccf74c40a8e3",
      "metadata": {
        "id": "b927a7ab-fbdc-4dab-b5bb-ccf74c40a8e3"
      },
      "outputs": [],
      "source": [
        "docs.plot_embeddings(image_sprites=True, image_source=\"uri\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03f64747-90f4-469a-a28a-1d2d7355c02e",
      "metadata": {
        "id": "03f64747-90f4-469a-a28a-1d2d7355c02e"
      },
      "source": [
        "As we can see, most items are in more or less the position you'd expect, and are clustered according to type.\n",
        "\n",
        "‚ö†Ô∏è To continue, stop the notebook (since the embedding animation blocks the script), then continue from this cell with:\n",
        "\n",
        "- *Runtime* ‚ñ∂Ô∏è *Run after* (in Google Colab)\n",
        "- *Run* ‚ñ∂Ô∏è *Run selected cell and all below* (In Jupyter Lab)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f63caffa-3aa5-4d50-aac9-3ebedd4cb16f",
      "metadata": {
        "id": "f63caffa-3aa5-4d50-aac9-3ebedd4cb16f"
      },
      "source": [
        "### Examine layers\n",
        "\n",
        "Resnet is a classification model. However, we don't want to train the final (classification) layer, but rather the embedding before that. As we can see below, that layer is called `adaptiveavgpool2d_173` for `resnet50`. We'll set this as our `LAYER_NAME` variable which we'll later use in `ft.fit()`.\n",
        "\n",
        "---\n",
        "\n",
        "‚ÑπÔ∏è Different models will have different layer names. So if you used `resnet18` (for example), your `LAYER_NAME` would be `adaptiveavgpool2d_67`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33513060-a207-4999-99b6-c6a7c40f8569",
      "metadata": {
        "id": "33513060-a207-4999-99b6-c6a7c40f8569"
      },
      "outputs": [],
      "source": [
        "# Let's look at the layers\n",
        "import finetuner as ft\n",
        "ft.display(model, (3, 80, 60))\n",
        "\n",
        "LAYER_NAME = \"adaptiveavgpool2d_173\" # second to last layer name"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67a11896-e618-4a57-9f82-b48c4c433964",
      "metadata": {
        "id": "67a11896-e618-4a57-9f82-b48c4c433964"
      },
      "source": [
        "## üìâ Finetune model\n",
        "\n",
        "Here's where the new stuff kicks in!\n",
        "\n",
        "We'll:\n",
        "\n",
        "- Set some basic parameters\n",
        "- Install a module to see progress\n",
        "- Finetune our model, focusing on the embedding layer *just* before the classification layer"
      ]
    },
    {
      "cell_type": "code",
      "id": "54c78255-a603-44e5-a372-9eb1226ee683",
      "metadata": {
        "id": "54c78255-a603-44e5-a372-9eb1226ee683"
      },
      "outputs": [],
      "source": [
        "# Basic setup\n",
        "EPOCHS = 40         # higher = more time, better finetuning\n",
        "BATCH_SIZE = 64    # higher = use more memory"
      ]
    },
    {
      "cell_type": "code",
      "id": "bb9fb1cf-f9cb-4233-a00d-5ecea5144a83",
      "metadata": {
        "id": "bb9fb1cf-f9cb-4233-a00d-5ecea5144a83"
      },
      "outputs": [],
      "source": [
        "# See progress bar in notebook\n",
        "!pip install -q ipywidgets # -q = quiet\n",
        "import ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to configure learning rate optimizer and scheduler\n",
        "def configure_optimizer(model):\n",
        "    # Here we use Adam optimizer to \n",
        "    optimizer = Adam(model.parameters(), lr=5e-4)\n",
        "    scheduler = MultiStepLR(optimizer, milestones=[10, 20], gamma=0.5)\n",
        "\n",
        "    return optimizer, scheduler"
      ],
      "metadata": {
        "id": "1iGrG6RxLB11"
      },
      "id": "1iGrG6RxLB11",
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the object for loss function \n",
        "loss = TripletLoss(\n",
        "    miner=TripletEasyHardMiner(pos_strategy='easy', neg_strategy='semihard')\n",
        ")"
      ],
      "metadata": {
        "id": "iaCthhTWLduX"
      },
      "id": "iaCthhTWLduX",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a5ac4a2-5ee9-4693-86b5-627340aa2571",
      "metadata": {
        "id": "1a5ac4a2-5ee9-4693-86b5-627340aa2571"
      },
      "outputs": [],
      "source": [
        "tuned_model = ft.fit(\n",
        "    model=model,\n",
        "    train_data=docs,\n",
        "    loss=loss,\n",
        "    configure_optimizer=configure_optimizer,\n",
        "    epochs=EPOCHS,\n",
        "    device=DEVICE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    to_embedding_model=True,\n",
        "    input_size=(3, 80, 60),\n",
        "    layer_name=LAYER_NAME, # layer before fc as feature extractor\n",
        "    freeze=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ba3e958-f738-4a44-9bf4-542da0304c02",
      "metadata": {
        "id": "0ba3e958-f738-4a44-9bf4-542da0304c02"
      },
      "source": [
        "### See embeddings\n",
        "\n",
        "Now that we've tuned the model, let's clear out our old embeddings and look at the new ones. \n",
        "\n",
        "‚ö†Ô∏è Unfortunately this doesn't play nice in Google Colab, only Jupyter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93591c4a-2d82-44d7-ae1f-8ee9a1630f50",
      "metadata": {
        "id": "93591c4a-2d82-44d7-ae1f-8ee9a1630f50"
      },
      "outputs": [],
      "source": [
        "for doc in docs:\n",
        "    doc.embedding = None\n",
        "    \n",
        "docs.embed(model, device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8589102f-734a-4bd1-b94c-2969d021a8f5",
      "metadata": {
        "id": "8589102f-734a-4bd1-b94c-2969d021a8f5"
      },
      "outputs": [],
      "source": [
        "docs.plot_embeddings(image_sprites=True, image_source=\"uri\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be37baa1-ff31-4ab3-b0e6-a0db3f40d6d5",
      "metadata": {
        "tags": [],
        "id": "be37baa1-ff31-4ab3-b0e6-a0db3f40d6d5"
      },
      "source": [
        "Now you can see a much starker delineation based on our input label.\n",
        "\n",
        "‚ö†Ô∏è If you can see the embedding animation above, you'll need to stop the notebook (since the embedding animation blocks the script), then continue from this cell with:\n",
        "\n",
        "- *Runtime* ‚ñ∂Ô∏è *Run after* (in Google Colab)\n",
        "- *Run* ‚ñ∂Ô∏è *Run selected cell and all below* (In Jupyter Lab)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25bb65c8-e54d-46e3-aca2-6921eb5064fa",
      "metadata": {
        "tags": [],
        "id": "25bb65c8-e54d-46e3-aca2-6921eb5064fa"
      },
      "source": [
        "## üíæ Save model"
      ]
    },
    {
      "cell_type": "code",
      "id": "8978b4c8-d33b-4ef3-b178-3cd787688c6e",
      "metadata": {
        "id": "8978b4c8-d33b-4ef3-b178-3cd787688c6e"
      },
      "outputs": [],
      "source": [
        "MODEL_FILENAME = \"tuned-model\"\n",
        "torch.save(tuned_model, MODEL_FILENAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9629e25-74ae-4e0d-b95b-52bb27b12252",
      "metadata": {
        "id": "d9629e25-74ae-4e0d-b95b-52bb27b12252"
      },
      "outputs": [],
      "source": [
        "# If running in Colab, download to local filesystem\n",
        "if in_colab:\n",
        "    files.download(\"tuned-model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f052a98-16df-43ea-8fb8-99da9fcc8c50",
      "metadata": {
        "id": "5f052a98-16df-43ea-8fb8-99da9fcc8c50"
      },
      "source": [
        "## ‚è≠Ô∏è Next steps\n",
        "\n",
        "Next we'll:\n",
        "\n",
        "- Load the tuned model into our original script\n",
        "- Compare results with the base model"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "colab": {
      "name": "labeled_finetuning.ipynb",
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}